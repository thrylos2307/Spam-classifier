{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam Classifier\n",
    "The goal is to classify the message as spam or non-spam using multinomial Naive Bayes algorithm.\n",
    "\n",
    "To classify messages as spam or non-spam ,we follow these steps to achieve our goal:-\n",
    "* Learns how humans classify messages.\n",
    "* Uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "* Classifies a new message based on these probability values — if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may need a human to classify the message).\n",
    "\n",
    "So our first task is to \"teach\" the computer how to classify messages. To do that, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the authors' papers.\n",
    "\n",
    "Lets start by exploring data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "sms_data= pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "  Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "ham     86.593683\n",
      "spam    13.406317\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sms_data.shape)\n",
    "print(sms_data.head())\n",
    "print(sms_data['Label'].value_counts(normalize='True')*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that thier are 13.4% message which are spam and other are non-spam(ham)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to test how good it is with classifying new messages. To test the spam filter, we are first going to split our dataset into two categories:\n",
    "* A training set, which we will use to \"train\" the computer how to classify messages.\n",
    "* A test set, which we will use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "We're going to keep 80% of our dataset for training, and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label                                                SMS\n",
      "0      ham                       Yep, by the pretty sculpture\n",
      "1      ham      Yes, princess. Are you going to make me moan?\n",
      "2      ham                         Welp apparently he retired\n",
      "3      ham                                            Havent.\n",
      "4      ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
      "5      ham  Ok i thk i got it. Then u wan me 2 come now or...\n",
      "6      ham  I want kfc its Tuesday. Only buy 2 meals ONLY ...\n",
      "7      ham                         No dear i was sleeping :-P\n",
      "8      ham                          Ok pa. Nothing problem:-)\n",
      "9      ham                    Ill be there on  &lt;#&gt;  ok.\n",
      "10     ham  My uncles in Atlanta. Wish you guys a great se...\n",
      "11     ham                                           My phone\n",
      "12     ham                       Ok which your another number\n",
      "13     ham  The greatest test of courage on earth is to be...\n",
      "14     ham  Dai what this da.. Can i send my resume to thi...\n",
      "15     ham                      I am late. I will be there at\n",
      "16    spam  FreeMsg Why haven't you replied to my text? I'...\n",
      "17     ham                  K, text me when you're on the way\n",
      "18    spam  Congrats! 2 mobile 3G Videophones R yours. cal...\n",
      "19     ham  Please leave this topic..sorry for telling that..\n",
      "20     ham  Ooooooh I forgot to tell u I can get on yovill...\n",
      "21     ham          Hi this is yijue, can i meet u at 11 tmr?\n",
      "22     ham  I want to show you the world, princess :) how ...\n",
      "23     ham                  Well that must be a pain to catch\n",
      "24     ham                Well. You know what i mean. Texting\n",
      "25     ham         Your bill at 3 is £33.65 so thats not bad!\n",
      "26     ham                       Yeah, where's your class at?\n",
      "27     ham                                     What's ur pin?\n",
      "28     ham  Fighting with the world is easy, u either win ...\n",
      "29     ham  Dude. What's up. How Teresa. Hope you have bee...\n",
      "...    ...                                                ...\n",
      "4428   ham                Uncle Abbey! Happy New Year. Abiola\n",
      "4429   ham             From tomorrow onwards eve 6 to 3 work.\n",
      "4430   ham                      Haha, just what I was thinkin\n",
      "4431   ham                           Happy New Year Princess!\n",
      "4432   ham  Let me know how to contact you. I've you settl...\n",
      "4433  spam  I don't know u and u don't know me. Send CHAT ...\n",
      "4434   ham         Yes! How is a pretty lady like you single?\n",
      "4435   ham                             Just getting back home\n",
      "4436   ham                         Oh my God. I'm almost home\n",
      "4437  spam  Congratulations YOU'VE Won. You're a Winner in...\n",
      "4438   ham  I cant pick the phone right now. Pls send a me...\n",
      "4439  spam  Win the newest “Harry Potter and the Order of ...\n",
      "4440   ham                    Dear umma she called me now :-)\n",
      "4441   ham                        Aight, lemme know what's up\n",
      "4442   ham  Good evening Sir, hope you are having a nice d...\n",
      "4443  spam  Someone U know has asked our dating service 2 ...\n",
      "4444   ham         2marrow only. Wed at  &lt;#&gt;  to 2 aha.\n",
      "4445   ham        Haha yeah I see that now, be there in a sec\n",
      "4446   ham                        aathi..where are you dear..\n",
      "4447   ham  Pls give her the food preferably pap very slow...\n",
      "4448   ham             I donno its in your genes or something\n",
      "4449  spam  YOUR CHANCE TO BE ON A REALITY FANTASY SHOW ca...\n",
      "4450   ham                             Prakesh is there know.\n",
      "4451   ham  The beauty of life is in next second.. which h...\n",
      "4452   ham             How about clothes, jewelry, and trips?\n",
      "4453   ham  Sorry, I'll call later in meeting any thing re...\n",
      "4454   ham  Babe! I fucking love you too !! You know? Fuck...\n",
      "4455  spam  U've been selected to stay in 1 of 250 top Bri...\n",
      "4456   ham  Hello my boytoy ... Geeee I miss you already a...\n",
      "4457   ham                           Wherre's my boytoy ? :-(\n",
      "\n",
      "[4458 rows x 2 columns]\n",
      "     Label                                                SMS\n",
      "0      ham          Later i guess. I needa do mcat study too.\n",
      "1      ham             But i haf enuff space got like 4 mb...\n",
      "2     spam  Had your mobile 10 mths? Update to latest Oran...\n",
      "3      ham  All sounds good. Fingers . Makes it difficult ...\n",
      "4      ham  All done, all handed in. Don't know if mega sh...\n",
      "5      ham  But my family not responding for anything. Now...\n",
      "6      ham                                           U too...\n",
      "7      ham  Boo what time u get out? U were supposed to ta...\n",
      "8      ham  Genius what's up. How your brother. Pls send h...\n",
      "9      ham                             I liked the new mobile\n",
      "10     ham                          For my family happiness..\n",
      "11     ham  If i let you do this, i want you in the house ...\n",
      "12     ham  Do you know why god created gap between your f...\n",
      "13     ham  K and you're sure I don't have to have consent...\n",
      "14     ham                                    Try neva mate!!\n",
      "15     ham  Haha... They cant what... At the most tmr forf...\n",
      "16     ham  Doc prescribed me morphine cause the other pai...\n",
      "17     ham  Spending new years with my brother and his fam...\n",
      "18     ham           and  picking them up from various points\n",
      "19    spam  Dear Dave this is your final notice to collect...\n",
      "20     ham                             At 7 we will go ok na.\n",
      "21     ham          Are you willing to go for aptitude class.\n",
      "22     ham                          Are you comingdown later?\n",
      "23     ham   You are a very very very very bad girl. Or lady.\n",
      "24     ham        Yo! Howz u? girls never rang after india. L\n",
      "25     ham                                          Ok can...\n",
      "26     ham  A bit of Ur smile is my hppnss, a drop of Ur t...\n",
      "27     ham          Guessin you ain't gonna be here before 9?\n",
      "28    spam  URGENT! You have won a 1 week FREE membership ...\n",
      "29     ham  THING R GOOD THANX GOT EXAMS IN MARCH IVE DONE...\n",
      "...    ...                                                ...\n",
      "1084   ham  Can not use foreign stamps in this country. Go...\n",
      "1085   ham                    S s..first time..dhoni rocks...\n",
      "1086  spam  Urgent! Please call 09061743811 from landline....\n",
      "1087   ham  I got like $ &lt;#&gt; , I can get some more l...\n",
      "1088   ham  Wow ... I love you sooo much, you know ? I can...\n",
      "1089   ham                        Dont gimme that lip caveboy\n",
      "1090   ham           Die... Now i have e toot fringe again...\n",
      "1091   ham  I know I'm lacking on most of this particular ...\n",
      "1092   ham                   Thanx 4 e brownie it's v nice...\n",
      "1093   ham                         Prepare to be pleasured :)\n",
      "1094  spam  Text BANNEDUK to 89555 to see! cost 150p texto...\n",
      "1095   ham  Wen ur lovable bcums angry wid u, dnt take it ...\n",
      "1096   ham  Bognor it is! Should be splendid at this time ...\n",
      "1097   ham  I'm doing da intro covers energy trends n pros...\n",
      "1098   ham  I've told you everything will stop. Just dont ...\n",
      "1099   ham  Do u konw waht is rael FRIENDSHIP Im gving yuo...\n",
      "1100   ham           As in i want custom officer discount oh.\n",
      "1101   ham                               I know she called me\n",
      "1102   ham  K.. I yan jiu liao... Sat we can go 4 bugis vi...\n",
      "1103   ham  Tell your friends what you plan to do on Valen...\n",
      "1104   ham  Double eviction this week - Spiral and Michael...\n",
      "1105   ham         I know you are. Can you pls open the back?\n",
      "1106   ham  Am on a train back from northampton so i'm afr...\n",
      "1107   ham                   K...k...yesterday i was in cbe .\n",
      "1108   ham  ARR birthday today:) i wish him to get more os...\n",
      "1109   ham  We're all getting worried over here, derek and...\n",
      "1110   ham  Oh oh... Den muz change plan liao... Go back h...\n",
      "1111   ham  CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
      "1112  spam  Text & meet someone sexy today. U can find a d...\n",
      "1113   ham                            K k:) sms chat with me.\n",
      "\n",
      "[1114 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data_sample=sms_data.sample(frac=1,random_state=1)\n",
    "random_data=round(len(data_sample)*0.8)\n",
    "train_set=data_sample[:random_data].reset_index(drop=True)\n",
    "test_set=data_sample[random_data:].reset_index(drop=True)\n",
    "print(train_set)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_set['Label'].value_counts(normalize=True))\n",
    "print(test_set['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate all these probabilities, we'll first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need. Right now, our training and test sets have this format\n",
    "![Image][1]\n",
    "[1]:https://dq-content.s3.amazonaws.com/433/cpgp_dataset_3.png\n",
    "\n",
    "We remove other char such as punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['SMS']=train_set['SMS'].str.replace('\\W',\" \")\n",
    "train_set['SMS']=train_set['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating col with require all unique words in the message(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set['SMS']=train_set['SMS'].str.split()\n",
    "vocabulary = []\n",
    "for sms in train_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_col=pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set=pd.concat([train_set,word_col],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability values of the two equations below to be able to classify new messages:\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "Also, to calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we need to use these equations:\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "Some of the terms in the four equations above will have the same value for every new message. As a start, let's first calculate:\n",
    "\n",
    "P(Spam), P(Ham),\n",
    "NSpam, NHam and  NVocabulary\n",
    "* NSpam is equal to the number of words in all the spam messages \n",
    "* NHam is equal to the number of words in all the non-spam messages  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob=training_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_ham,p_spam=prob[0],prob[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_messages = training_set[training_set['Label'] == 'spam']\n",
    "ham_messages = training_set[training_set['Label'] == 'ham']\n",
    "spam_word=spam_messages['SMS'].apply(len)\n",
    "n_spam=spam_word.sum()\n",
    "\n",
    "ham_word=ham_messages['SMS'].apply(len)\n",
    "n_ham=ham_word.sum()\n",
    "\n",
    "n_vocabulary=len(vocabulary)\n",
    "alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the constant terms calculated above, we can move on with calculating the parameters $P(w_i|Spam)$ and $P(w_i|Ham)$. Each parameter will thus be a conditional probability value associated with each word in the vocabulary.\n",
    "\n",
    "The parameters are calculated using the formulas:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_spam={word:0 for word in vocabulary}\n",
    "param_ham={word:0 for word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in vocabulary:\n",
    "    spam_w=spam_messages[word].sum()\n",
    "    p_w_given_spam=(spam_w+alpha)/(n_spam+alpha*n_vocabulary)\n",
    "    param_spam[word]=p_w_given_spam\n",
    "   \n",
    "    ham_w=ham_messages[word].sum()\n",
    "    p_w_given_ham=(ham_w+alpha)/(n_ham+alpha*n_vocabulary)\n",
    "    param_ham[word]=p_w_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've calculated all the constants and parameters we need,The spam filter can be understood as a function that:\n",
    "\n",
    "Takes in as input a new message (w1, w2, ..., wn)\n",
    "Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "* If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "* If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "* If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help.\n",
    "\n",
    "Note:some new messages will contain words that are not part of the vocabulary,we simply ignore these words when we're calculating the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message=p_spam\n",
    "    p_ham_given_message=p_ham\n",
    "    for word in message:\n",
    "        if word in param_spam:\n",
    "            p_spam_given_message*=param_spam[word]\n",
    "        if word in param_ham:\n",
    "            p_ham_given_message*=param_ham[word]\n",
    "        \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test the classifier to classify message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll determine how well the spam filter does on our test set of 1,114 messages.\n",
    "The algorithm will output a classification label for every message in our test set, which we'll be able to compare with the actual label (given by a human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in param_spam:\n",
    "            p_spam_given_message *= param_spam[word]\n",
    "\n",
    "        if word in param_ham:\n",
    "            p_ham_given_message *= param_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct :  1100\n",
      "Total messages: 1114\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "total_test_case=test_set.shape[0]\n",
    "correct=0\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label']==row['predicted']:\n",
    "        correct+=1\n",
    "        \n",
    "print(\"correct : \",correct)\n",
    "print(\"Total messages:\",total_test_case)\n",
    "print(\"Accuracy:\",correct/total_test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is close to 98.74%, which is really good. Our spam filter looked at 1,114 messages that it hasn't seen in training, and classified 1,100 correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}